# Arquitectura del Sistema - TalentPitch Recommendation Service

## ğŸ“ Arquitectura General

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FastAPI Server                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Endpoints  â”‚  â”‚  Background  â”‚  â”‚  Middleware      â”‚   â”‚
â”‚  â”‚            â”‚â†’ â”‚  Tasks       â”‚  â”‚  (CORS, Flush)   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                â”‚                  â”‚
         â”‚                â”‚                  â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚  Data   â”‚    â”‚ Recommen-   â”‚   â”‚  Activity   â”‚
    â”‚ Service â”‚    â”‚ dation      â”‚   â”‚  Tracker    â”‚
    â”‚         â”‚    â”‚ Engine      â”‚   â”‚             â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
         â”‚                â”‚                  â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚     In-Memory Data (Pandas DataFrames)      â”‚
    â”‚  users_df, videos_df, interactions_df,     â”‚
    â”‚  connections_df, flows_df, embeddings       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚           â”‚           â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”
    â”‚  MySQL  â”‚ â”‚  Redis â”‚  â”‚ Configâ”‚
    â”‚ (SSH)   â”‚ â”‚ (SSH)  â”‚  â”‚       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Ciclo de Vida de la AplicaciÃ³n

### Startup

```
1. Load Config (.env)
   â”œâ”€ Set environment (staging/prod)
   â”œâ”€ Load credentials
   â””â”€ Initialize paths

2. Establish Connections
   â”œâ”€ MySQL via SSH tunnel
   â””â”€ Redis via SSH tunnel

3. Load Data (DataService)
   â”œâ”€ Query users, videos, interactions
   â”œâ”€ Load connections, flows
   â”œâ”€ Parse JSON fields
   â””â”€ Normalize data

4. Initialize Recommendation Engine
   â”œâ”€ Build skill embeddings
   â”œâ”€ Construct social graph
   â”œâ”€ Pre-calculate advanced scores
   â””â”€ Initialize bandits (VMP, AU, NU)

5. Setup FastAPI
   â”œâ”€ Register endpoints
   â”œâ”€ Setup CORS
   â””â”€ Start background flush task

6. Ready to serve requests
```

### Request Flow

```
Client Request
     â”‚
     â”œâ”€â†’ Parse parameters (user_id, excluded_ids)
     â”‚
     â”œâ”€â†’ Get RecommendationEngine singleton
     â”‚
     â”œâ”€â†’ Get user preferences (history, skills)
     â”‚
     â”œâ”€â†’ Generate feed with bandits:
     â”‚     â”œâ”€ VMP pool (popular)
     â”‚     â”œâ”€ AU pool (personalized)
     â”‚     â”œâ”€ NU pool (new)
     â”‚     â”œâ”€ FW pool (flows)
     â”‚     â””â”€ EXPLORE pool (random)
     â”‚
     â”œâ”€â†’ Apply diversity constraints
     â”‚
     â”œâ”€â†’ Format response (mix_ids, items)
     â”‚
     â”œâ”€â†’ Track activities in Redis
     â”‚
     â”œâ”€â†’ Check flush threshold (50+ activities)
     â”‚
     â””â”€â†’ Return response to client
```

## ğŸ§  Motor de Recomendaciones

### Bandit Contextual Adaptativo

```python
class BanditContextualAdaptativo:
    - n_features: 18
    - alpha: parÃ¡metro de exploraciÃ³n
    - beta: parÃ¡metro de adaptaciÃ³n
    - A: matriz Ridge Regression (18x18)
    - b: vector de recompensas
    - theta: parÃ¡metros del modelo
    - A_inv: inversa de A para UCB
```

### LinUCB (Linear Upper Confidence Bound)

```
UCB = Î¼ + Î± * âˆš(x^T * A^(-1) * x) + Î² * varianza_adaptativa

Donde:
- Î¼ = reward esperado (contexto * theta)
- Î± = nivel de exploraciÃ³n
- x = features del item
- A^(-1) = inversa de matriz Ridge
- Î² = adaptaciÃ³n segÃºn varianza
```

### Feature Engineering (18 features)

```python
features = np.zeros((n_candidatos, 18))

features[:, 0] = score_engagement          # Views + Rating + Connections
features[:, 1] = score_temporal            # Days since creation
features[:, 2] = score_calidad             # Rating quality gate
features[:, 3] = score_popularidad         # Popularity score
features[:, 4] = diversidad_skills         # Skill diversity
features[:, 5] = similitud_skills          # User-video skill match
features[:, 6] = match_extendido           # Match score (skills+knowledge+tools+langs)
features[:, 7] = coincidencia_ciudad       # City match
features[:, 8] = seÃ±ales_sociales          # Social connections
features[:, 9] = log(views) / 10
features[:, 10] = rating / 5
features[:, 11] = rareza_skills            # Skill rarity
features[:, 12] = pasa_gate_calidad        # Quality gate
features[:, 13] = influencia_social         # Social influence
features[:, 14] = rating_count / max
features[:, 15] = like_count / max
features[:, 16] = exhibited_count / max
features[:, 17] = random_exploration       # Random boost
```

### Pool Selection Strategy

#### VMP (Valued Products)

**ParÃ¡metros**: Î±=1.5, Î²=0.8

**SelecciÃ³n**:
```python
1. Filter por gate de calidad
2. Calcular UCB score con bandit VMP
3. Combinar: UCB + engagement*2.2 + popularidad*1.6 + calidad*1.8
4. Boost contenido <45 dÃ­as: +1.4
5. Weighted sampling de top candidatos
```

#### AU (Affine to User)

**ParÃ¡metros**: Î±=1.8, Î²=1.0

**SelecciÃ³n**:
```python
1. Calcular UCB score con bandit AU
2. Combinar: UCB + similitud_skills*2.8 + match_extendido*2.5
3. Boost contenido nuevo: +0.9
4. Return top N por score
```

#### NU (Nuevo)

**ParÃ¡metros**: Î±=2.5, Î²=1.3

**SelecciÃ³n**:
```python
1. Filter solo contenido <45 dÃ­as
2. Calcular UCB score con bandit NU
3. Combinar: UCB + temporal*2.5 + diversidad*1.8 + rareza*1.4
4. Random exploration boost: +0.6
5. Sample aleatorio de top candidatos
```

#### FW (Flows)

**SelecciÃ³n**:
```python
1. Filter flows (no videos)
2. Score = random(0,40) + temporal*60
3. Sort by score
4. Return top N
```

## ğŸ—„ï¸ Modelo de Datos

### DataFrames en Memoria

#### users_df

```python
columns = [
    'id', 'name', 'city', 'country', 'created_at',
    'skills', 'languages', 'tools', 'knowledge',
    'hobbies', 'type_talentees', 'opencall_objective'
]
```

#### videos_df

```python
columns = [
    'id', 'user_id', 'video', 'views', 'video_skills',
    'video_knowledges', 'video_tools', 'video_languages',
    'role_objectives', 'created_at', 'description',
    'creator_city', 'creator_country', 'creator_name',
    'avg_rating', 'rating_count', 'connection_count',
    'like_count', 'exhibited_count', 'city',
    'days_since_creation', 'score_engagement',
    'score_temporal', 'boost_nuevo', 'score_calidad',
    'score_popularidad', 'diversidad_skills',
    'rareza_skills', 'pasa_gate_calidad'
]
```

#### interactions_df

```python
columns = [
    'user_id', 'video_id', 'rating',
    'created_at', 'interaction_type'
]
```

#### connections_df

```python
columns = [
    'user_id', 'connected_user_id', 'status', 'created_at'
]
```

#### flows_df

```python
columns = [
    'id', 'user_id', 'video', 'name', 'description',
    'created_at', 'creator_name', 'creator_city',
    'creator_country', 'city', 'days_since_creation'
]
```

## ğŸ”„ Tracking y Flush

### Redis Keys

```
user_activity:{user_id}        # List of activities (TTL: 24h)
session:{user_id}:{timestamp}  # Session data (TTL: 1h)
```

### Activity Structure

```json
{
  "event_type": "video_view" | "feed_request",
  "user_id": int,
  "video_id": int,  # for video_view
  "video_url": str,
  "position": int,
  "feed_type": str,
  "timestamp": "ISO8601",
  "session_id": str
}
```

### Flush Process

```
1. Accumulate activities in Redis
   â””â”€ LPUSH user_activity:{user_id} <activity_json>

2. Check flush conditions
   â”œâ”€ Activity count >= 50
   â””â”€ Every 15 minutes (background task)

3. Transfer to MySQL
   â”œâ”€ Connect to MySQL
   â”œâ”€ For each activity in Redis:
   â”‚   â””â”€ INSERT INTO activity_log (...)
   â””â”€ DELETE user_activity:{user_id}

4. Log result
   â””â”€ Log inserted count
```

## ğŸ” Seguridad

### SSH Tunnels

**MySQL Tunnel**:
```
Local App â†â†’ SSH Tunnel â†â†’ MySQL Server
  127.0.0.1:random   Bastion   10.x.x.x:3306
```

**Redis Tunnel**:
```
Local App â†â†’ SSH Tunnel â†â†’ Redis Server
  127.0.0.1:random   Bastion   10.x.x.x:6379
```

### ConfiguraciÃ³n

```python
# SSH Tunnel
tunnel = SSHTunnelForwarder(
    (ssh_host, 22),
    ssh_username=ssh_user,
    ssh_pkey=path_to_pem,
    remote_bind_address=(target_host, target_port),
    local_bind_address=('127.0.0.1', 0)  # random port
)
tunnel.start()

# MySQL Connection (via tunnel)
mysql_conn = pymysql.connect(
    host='127.0.0.1',
    port=tunnel.local_bind_port,
    user=mysql_user,
    password=mysql_password,
    db=mysql_db
)

# Redis Connection (via tunnel + SSL)
redis_client = redis.Redis(
    host='127.0.0.1',
    port=tunnel.local_bind_port,
    password=redis_password,
    ssl=(REDIS_SCHEME == 'tls'),
    db=1
)
```

## âš¡ Optimizaciones Implementadas

### 1. Pre-cÃ¡lculo de Scores

- Calcular una vez al inicio
- Guardar en columnas de DataFrame
- Evitar re-computaciÃ³n en cada request

### 2. Embeddings de Skills

- Construir matriz de co-ocurrencia
- Normalizar embeddings
- Cache para lookups O(1)

### 3. Social Graph

- Pre-construir grafo en startup
- Calcular influencia social
- Lookups rÃ¡pidos en recomendaciones

### 4. VectorizaciÃ³n

- Operaciones batch con NumPy
- Pandas vectorized operations
- Minimizar loops Python

### 5. Singleton Pattern

- Una instancia de cada servicio
- Reutilizar conexiones
- Reducir overhead

### 6. Connection Pooling

- Reutilizar conexiones SSH
- Cache de queries
- Close connections cuando sea necesario

## ğŸ“Š MÃ©tricas de Rendimiento

### Targets

| MÃ©trica | Target | Actual |
|---------|--------|--------|
| Feed generation | < 0.2s | ~0.15s |
| Data reload | < 60s | ~35s |
| API response | < 0.3s | ~0.2s |
| Memory usage | < 1GB | ~600MB |
| Creator diversity | 100% | 100% |
| Skill diversity | 60-75% | ~65% |
| Catalog coverage | 25-35% | ~28% |
| New content ratio | 25-35% | ~30% |

### Escalabilidad

- **Horizontal**: Agregar workers (Gunicorn)
- **Vertical**: Aumentar memoria para mÃ¡s datos
- **Cache**: Redis ya implementado
- **DB**: Actualizar sin restart (reload endpoint)

## ğŸ› Manejo de Errores

### Error Handling Levels

1. **Connection Errors**
   - Log error
   - Retry con backoff
   - Fallback a valores por defecto

2. **Data Errors**
   - Log warning
   - Skip item problemÃ¡tico
   - Continuar con resto

3. **Query Errors**
   - Log error
   - Return empty results
   - No fallar request completo

4. **Track Errors**
   - Log error
   - No bloquear respuesta
   - Reintentar en prÃ³ximo flush

## ğŸ“ˆ Monitoring

### Logs

- **File**: `logs/talent.log`
- **Format**: `<timestamp> - <module> - <level> - <message>`
- **Timezone**: GMT-5
- **Rotation**: Manual (Docker volumes)

### Metrics to Track

- Response times
- Error rates
- Memory usage
- Database connection health
- Redis connection health
- Activities flushed count
- Bandit performance stats

## ğŸ”§ Configuration Management

### Environment Variables

```python
# Load from credentials/.env
env_path = project_root / 'credentials' / '.env'
load_dotenv(env_path)

# Use simple variable names
mysql_host = os.getenv('MYSQL_HOST')
mysql_user = os.getenv('MYSQL_USER')
mysql_password = os.getenv('MYSQL_PASSWORD')
mysql_db = os.getenv('MYSQL_DB')
# ... etc
```

### Config Singleton

```python
class Config:
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(Config, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        if hasattr(self, '_initialized'):
            return
        self._initialized = True
        # Load all env vars
```

## ğŸ¯ PatrÃ³n de RecomendaciÃ³n

### Feed Pattern

```
PATRON: [VMP, AU, AU, VMP, NU, FW]
REPETICIONES: 4 veces = 24 items

Ejemplo de feed:
1.  VMP  - Video popular #1
2.  AU   - Video personalizado #1
3.  AU   - Video personalizado #2
4.  VMP  - Video popular #2
5.  NU   - Video nuevo
6.  FW   - Challenge
7.  VMP  - Video popular #3
8.  AU   - Video personalizado #3
...
24. FW   - Challenge
```

### Diversity Constraints

- **No repite creador**: Ventana deslizante de 12 items
- **No repite video**: Set de IDs usados
- **Diversidad skills**: Target 60-75%
- **Sin duplicados**: Check antes de agregar

---

**Ãšltima actualizaciÃ³n**: 2025  
**VersiÃ³n**: 2.0
